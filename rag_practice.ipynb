{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPNw/baRjjN6qMOOogcmuXS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Professor-Shin/AI-learning-practice/blob/main/rag_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Gd6rCG7RDydD",
        "outputId": "ecc29ae9-c05d-4693-a7de-23e9130c293a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.3/53.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.1/155.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.7/21.7 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.6/329.6 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.6/426.6 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.3/233.3 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m484.9/484.9 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# @title Step 1: Install Required Libraries\n",
        "!pip install -q -U google-generativeai langchain-google-genai chromadb pypdf langchain\n",
        "!pip install -q langchain-community langchain-text-splitters sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "print(langchain.__version__)"
      ],
      "metadata": {
        "id": "XVWH2zUzcm4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 2: Setup Google API Key securely\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "try:\n",
        "    # ดึง Key จาก Colab Secrets (วิธีที่แนะนำ)\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "    print(\"API Key ถูกตั้งค่าเรียบร้อยแล้ว\")\n",
        "except ImportError:\n",
        "    # กรณีไม่ได้ใช้ Secrets ให้ใส่ Key ตรงๆ (ไม่แนะนำสำหรับงานจริง)\n",
        "    print(\"ไม่พบ Colab Secrets, กรุณาใส่ Key โดยตรงใน Code (ถ้าจำเป็น)\")\n",
        "    # os.environ[\"GOOGLE_API_KEY\"] = \"PASTE_YOUR_KEY_HERE\" # ระวัง Key หลุด\n",
        "except KeyError:\n",
        "    print(\"Error: กรุณาสร้าง Secret ชื่อ 'GOOGLE_API_KEY' ในแถบด้านซ้ายก่อน\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBTXPNXbQ2Ty",
        "outputId": "7bbd1541-abd8-4696-d969-94aa816a2e49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API Key ถูกตั้งค่าเรียบร้อยแล้ว\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 3: Load and Split the PDF Document\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# --- 1. Loading ---\n",
        "# บอก LangChain ว่าไฟล์เราอยู่ที่ไหน\n",
        "loader = PyPDFLoader('/content/ABC Company.pdf')\n",
        "# สั่งให้โหลดเนื้อหาออกมา\n",
        "documents = loader.load()\n",
        "print(f\"โหลดไฟล์สำเร็จ: มีทั้งหมด {len(documents)} หน้า\")\n",
        "\n",
        "\n",
        "# --- 2. Splitting (Chunking) ---\n",
        "# เราต้องหั่นข้อความยาวๆ ให้สั้นลง เพื่อให้ AI อ่านรู้เรื่องและประหยัด Token\n",
        "# chunk_size=500: แต่ละชิ้นมีความยาวประมาณ 500 ตัวอักษร\n",
        "# chunk_overlap=50: ให้แต่ละชิ้นมีเนื้อหาซ้อนทับกัน 50 ตัวอักษร (เพื่อให้ประโยคไม่ขาดตอน)\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=50\n",
        ")\n",
        "\n",
        "# เริ่มทำการหั่น\n",
        "split_docs = text_splitter.split_documents(documents)\n",
        "\n",
        "print(f\"\\n--- ผลลัพธ์การหั่น ---\")\n",
        "print(f\"จากเอกสารต้นฉบับ หั่นออกมาได้ทั้งหมด: {len(split_docs)} ชิ้น (Chunks)\")\n",
        "\n",
        "# ลองดูตัวอย่างชิ้นที่ 2 (Index 1) ว่าหน้าตาเป็นยังไง\n",
        "print(f\"\\nตัวอย่างเนื้อหาชิ้นที่ 2:\\n---\")\n",
        "print(split_docs[1].page_content)\n",
        "print(\"---\")\n",
        "print(f\"ที่มาของชิ้นนี้: {split_docs[1].metadata}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vkvICKaVVVu",
        "outputId": "0a15ac4d-d85b-4062-e13c-d8d951c9a8a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "โหลดไฟล์สำเร็จ: มีทั้งหมด 1 หน้า\n",
            "\n",
            "--- ผลลัพธ์การหั่น ---\n",
            "จากเอกสารต้นฉบับ หั่นออกมาได้ทั้งหมด: 3 ชิ้น (Chunks)\n",
            "\n",
            "ตัวอย่างเนื้อหาชิ้นที่ 2:\n",
            "---\n",
            "4. Equipment and Security Employees must use company-issued laptops for work. Use of \n",
            "personal devices for accessing company data is strictly prohibited. Employees must ensure a \n",
            "secure internet connection (no public Wi-Fi without VPN).  \n",
            "5. Communication Employees must check Slack and Email regularly. Urgent matters should \n",
            "be communicated via phone call.  \n",
            "6. Performance Monitoring Managers will review output weekly. Consistent failure to meet\n",
            "---\n",
            "ที่มาของชิ้นนี้: {'producer': 'Adobe PDF Library 11.0', 'creator': 'Acrobat PDFMaker 11 for Word', 'creationdate': '2025-12-19T04:07:19+07:00', 'author': 'Siwakorn Saiphaisri', 'comments': '', 'company': '', 'keywords': '', 'moddate': '2025-12-19T04:07:24+07:00', 'sourcemodified': 'D:20251218210653', 'subject': '', 'title': '', 'source': '/content/ABC Company.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 4: Create Embeddings and Store in Vector DB\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "# 1. นิยามโมเดลที่จะใช้แปลงข้อความเป็นตัวเลข (Embedding Model)\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# 2. นำข้อมูลที่หั่นแล้ว (split_docs) ไปใส่ใน ChromaDB\n",
        "# กระบวนการนี้จะส่งข้อความไปให้ Google แปลงเป็นตัวเลขแล้วเก็บไว้ใน RAM ของ Colab\n",
        "vector_db = Chroma.from_documents(\n",
        "    documents=split_docs,\n",
        "    embedding=embeddings,\n",
        "    persist_directory=\"./chroma_db\" # เก็บข้อมูลไว้ในโฟลเดอร์นี้\n",
        ")\n",
        "\n",
        "print(\"สร้าง Vector Database และเก็บข้อมูลสำเร็จแล้ว!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t07uiDPZWl61",
        "outputId": "63f23797-560a-4b9e-e566-f4cb020e8094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4253278828.py:10: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "สร้าง Vector Database และเก็บข้อมูลสำเร็จแล้ว!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 5: Setup Chat Interface (RetrievalQA)\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_classic.chains.retrieval_qa.base import RetrievalQA\n",
        "\n",
        "\n",
        "# 1. เรียกใช้ Gemini 2.5 Flash\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)\n",
        "\n",
        "# 2. สร้างตัว 'Retriever' (ตัวค้นหาข้อมูล)\n",
        "# search_kwargs={\"k\": 2} คือให้ไปหยิบเนื้อหาที่ใกล้เคียงที่สุดมา 2 ชิ้น\n",
        "retriever = vector_db.as_retriever(search_kwargs={\"k\": 2})\n",
        "\n",
        "# 3. สร้าง Chain สำหรับการถามตอบ\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\", # เอา context ทั้งหมด 'ยัด' (stuff) เข้าไปใน Prompt\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True # ให้บอกด้วยว่าเอาคำตอบมาจากตรงไหน\n",
        ")\n",
        "\n",
        "print(\"ระบบ Chat Bot พร้อมทำงานแล้ว!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YWp0gf4YQXa",
        "outputId": "263cc97d-4742-4e50-a576-7fdca37f5f56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ระบบ Chat Bot พร้อมทำงานแล้ว!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 6: Test Your RAG System\n",
        "question = \"Who is eligible for WFH and how many days?\" # @param {type:\"string\"}\n",
        "\n",
        "# รันคำถามผ่านระบบ RAG\n",
        "result = qa_chain.invoke({\"query\": question})\n",
        "\n",
        "print(f\"คำถาม: {question}\")\n",
        "print(f\"คำตอบจาก Gemini: {result['result']}\")\n",
        "print(\"\\n--- อ้างอิงจากข้อมูลส่วนนี้ ---\")\n",
        "for doc in result['source_documents']:\n",
        "    print(f\"- {doc.page_content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "verZXOvoadrD",
        "outputId": "b4afb0ef-76e4-4410-9c93-f050d3049bdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "คำถาม: Who is eligible for WFH and how many days?\n",
            "คำตอบจาก Gemini: Full-time employees who have completed their probation period are eligible for up to 2 days of WFH per week, subject to manager approval.\n",
            "\n",
            "--- อ้างอิงจากข้อมูลส่วนนี้ ---\n",
            "- ABC Company - Work From Home (WFH) Policy 2024  \n",
            "1. Purpose This policy outlines the guidelines for employees working remotely to ensure \n",
            "productivity and data security.  \n",
            "2. Eligibility Full-time employees who have completed their probation period are eligible for \n",
            "up to 2 days of WFH per week, subject to manager approval.  \n",
            "3. Working Hours Remote employees must be available during core business hours (10:00 \n",
            "AM - 4:00 PM). They are expected to log 8 hours of work per day.\n",
            "- ABC Company - Work From Home (WFH) Policy 2024  \n",
            "1. Purpose This policy outlines the guidelines for employees working remotely to ensure \n",
            "productivity and data security.  \n",
            "2. Eligibility Full-time employees who have completed their probation period are eligible for \n",
            "up to 2 days of WFH per week, subject to manager approval.  \n",
            "3. Working Hours Remote employees must be available during core business hours (10:00 \n",
            "AM - 4:00 PM). They are expected to log 8 hours of work per day.\n"
          ]
        }
      ]
    }
  ]
}